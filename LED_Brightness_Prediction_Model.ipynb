{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv('input_data/train_data.csv')\n",
    "\n",
    "# Prepare the training data\n",
    "commands = train_data.iloc[:, 0].values\n",
    "brightness = train_data.iloc[:, 1].astype(int).values\n",
    "\n",
    "# Normalize brightness values to [0, 1]\n",
    "y_normalized = brightness / 100.0\n",
    "\n",
    "# Tokenize the commands\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(commands)\n",
    "sequences = tokenizer.texts_to_sequences(commands)\n",
    "\n",
    "# Pad the sequences to ensure uniform input size\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "X_train = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Load the validation data\n",
    "val_data = pd.read_csv('input_data/val_data.csv')\n",
    "\n",
    "# Prepare the validation data\n",
    "val_commands = val_data.iloc[:, 0].values\n",
    "val_brightness = val_data.iloc[:, 1].astype(int).values\n",
    "\n",
    "# Normalize brightness values to [0, 1]\n",
    "y_val_normalized = val_brightness / 100.0\n",
    "\n",
    "# Tokenize the validation commands\n",
    "val_sequences = tokenizer.texts_to_sequences(val_commands)\n",
    "X_val = pad_sequences(val_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.2))  # Dropout layer to reduce overfitting\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))  # Another dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Change to sigmoid if normalizing\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_normalized,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val_normalized),  # Add validation data\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('output_data/led_brightness_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('output_data/led_brightness_model.keras')\n",
    "\n",
    "# Make predictions on the validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Denormalize predictions to [0, 100] and round to two decimal places\n",
    "predicted_brightness = (predictions * 100.0).flatten()\n",
    "predicted_brightness_rounded = np.round(predicted_brightness, 2)\n",
    "\n",
    "# Calculate the difference between true brightness and predicted brightness\n",
    "brightness_difference = val_brightness - predicted_brightness_rounded\n",
    "\n",
    "# Display the results\n",
    "results = pd.DataFrame({\n",
    "    'Command': val_commands,\n",
    "    'True Brightness': val_brightness,\n",
    "    'Predicted Brightness': predicted_brightness_rounded,\n",
    "    'Difference': brightness_difference\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export trained data for Arduino or ESP32 boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join('LED_Controller', 'data')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('output_data/led_brightness_model.keras')\n",
    "\n",
    "# Check the model architecture\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Extract parameters (weights and biases for each layer)\n",
    "weights = []\n",
    "biases = []\n",
    "for layer in model.layers:\n",
    "    if 'dense' in layer.name:\n",
    "        w, b = layer.get_weights()\n",
    "        weights.append(w)\n",
    "        biases.append(b)\n",
    "# Save parameters as C++ arrays\n",
    "for i, (w, b) in enumerate(zip(weights, biases)):\n",
    "    weights_path = os.path.join(output_dir, f'dense_{i}_weights.h')\n",
    "    biases_path = os.path.join(output_dir, f'dense_{i}_biases.h')\n",
    "    np.savetxt(weights_path, w.flatten(), delimiter=',', header=f'Dense {i} weights', comments='')\n",
    "    np.savetxt(biases_path, b.flatten(), delimiter=',', header=f'Dense {i} biases', comments='')\n",
    "\n",
    "print(f\"Parameters were successfully saved to the folder: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
